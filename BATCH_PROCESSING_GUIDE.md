# Batch Processing Guide for DropletAnalyzer

This guide explains how to use the PowerShell scripts to process multiple experiment folders automatically.

## Directory Structure

Your dataset should be organized like this:

```
DatasetDirectory/
├── ProcessDropletImages.ps1          # Single folder processing script
├── ProcessDropletDataset.ps1         # Batch processing script (runs on all folders)
├── PICOINJ_3_1/                      # Experiment folder 1
│   ├── 0_20241203-104613-962_84_00145.jpg
│   ├── 0_20241203-104614-957_90_00139.jpg
│   └── ... (more images)
├── PICOINJ_3_2/                      # Experiment folder 2
│   ├── image1.jpg
│   └── ... (more images)
├── PICOINJ_3_3/                      # Experiment folder 3
│   └── ... (images)
└── ...
```

After processing, each folder will contain an `Outputs` subfolder with QC images.

## Scripts

### 1. ProcessDropletImages.ps1
Processes all images in a **single folder** (the current directory).

**Usage:**
```powershell
cd PICOINJ_3_1
..\ProcessDropletImages.ps1 -MaxCores 4
```

**Parameters:**
- `-MaxCores`: Number of CPU cores to use for parallel processing (default: 4)
- `-ImagePattern`: Image file pattern to match (default: "*.jpg")

### 2. ProcessDropletDataset.ps1
Processes **all experiment folders** in the current directory automatically.

**Usage:**
```powershell
# Run from the main dataset directory
.\ProcessDropletDataset.ps1 -MaxCores 4
```

**Parameters:**
- `-MaxCores`: Number of CPU cores to use for parallel processing (default: 4)
- `-ImagePattern`: Image file pattern to match (default: "*.jpg")
- `-SkipExisting`: Skip folders that already have an Outputs directory (default: false)

**Example with options:**
```powershell
# Use 8 cores and skip folders already processed
.\ProcessDropletDataset.ps1 -MaxCores 8 -SkipExisting

# Process only PNG files
.\ProcessDropletDataset.ps1 -ImagePattern "*.png"
```

## Complete Workflow

### Step 1: Set up your directory structure
1. Place both PowerShell scripts in your main dataset directory
2. Ensure each experiment has its own subfolder with images

### Step 2: Run batch processing
```powershell
# Navigate to your dataset directory
cd C:\Data\MyExperiments

# Run the batch processor
.\ProcessDropletDataset.ps1 -MaxCores 4
```

The script will:
- Find all experiment folders
- Process each folder sequentially
- Create an `Outputs` subfolder in each experiment folder
- Generate QC images with measurements in the filenames

### Step 3: Generate CSV output
After all experiments are processed, use the Python script to tabulate results:

```powershell
python ..\DropletAnalyzer_PY\MakeCSV.py Experiment_Template.csv . -o results.csv
```

## Output Structure

After processing, your directory will look like this:

```
DatasetDirectory/
├── ProcessDropletImages.ps1
├── ProcessDropletDataset.ps1
├── results.csv                       # Generated by Python script
├── PICOINJ_3_1/
│   ├── 0_20241203-104613-962_84_00145.jpg
│   ├── 0_20241203-104614-957_90_00139.jpg
│   └── Outputs/
│       ├── 1_VALID_40p50_103p25.jpg
│       ├── 2_VALID_25p00_160p50.jpg
│       ├── 3_INVALID_0p00_0p00.jpg
│       └── ...
├── PICOINJ_3_2/
│   ├── images...
│   └── Outputs/
│       └── QC images...
└── ...
```

## Troubleshooting

### "DropletAnalyzer executable not found"
- Make sure the C++ DropletAnalyzer program is built
- Default location: `C:\Dev\DropletAnalyzer\DropletAnalyzer_OCV\build\Debug\DropletAnalyzer.exe`
- The script will automatically look for Debug or Release builds

### "No subdirectories found to process"
- Make sure you're running from the correct directory (the parent of all experiment folders)
- Experiment folders should contain image files matching the pattern (default: *.jpg)

### Processing failed for specific folder
- Check if that folder contains valid image files
- Review the error messages for that specific folder
- You can rerun the script with `-SkipExisting` to process only failed folders

### Need to reprocess specific folders
1. Delete the `Outputs` folder from those experiment folders
2. Run the batch script again with `-SkipExisting` flag (or without it to reprocess everything)

## Performance Tips

- **Adjust MaxCores**: Use more cores for faster processing (e.g., `-MaxCores 8`)
- **Monitor resource usage**: Don't use all CPU cores; leave some for system operations
- **Large datasets**: The script processes folders sequentially but images within each folder in parallel
- **Resume capability**: Use `-SkipExisting` to skip already-processed folders

## Complete Example

```powershell
# 1. Navigate to dataset
cd C:\Data\DropletExperiments

# 2. Copy scripts to dataset directory
copy C:\Dev\DropletAnalyzer\ProcessDropletImages.ps1 .
copy C:\Dev\DropletAnalyzer\ProcessDropletDataset.ps1 .

# 3. Process all experiments
.\ProcessDropletDataset.ps1 -MaxCores 6

# 4. Generate CSV with Python
python C:\Dev\DropletAnalyzer\DropletAnalyzer_PY\MakeCSV.py Experiment_Template.csv . -o MyResults.csv

# 5. Results are now in MyResults.csv!
```

